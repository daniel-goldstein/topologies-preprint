\documentclass{article}

\usepackage{amsmath, amsfonts, amsthm}
\usepackage{algorithm, algpseudocode}

\newcommand{\tskit}{{\texttt{tskit}}}
\newcommand{\tsinfer}{{\texttt{tsinfer}}}
\newcommand{\msprime}{{\texttt{msprime}}}
\newcommand{\twisst}{{\textit{TWISST}}}

\begin{document}

\title{Efficiently Computing Species Trees Distributions Along the Genome}
\author{Daniel Goldstein}
\maketitle


\section{Introduction}

The inference of species trees from genomic data is a fundamental problem in
evolutionary biology. They reveal the genetic proximity and relationship
through time of different species and broaden our understanding of 
evolutionary processes. However, there does not generally exist one 
species tree that describes the evolution of a set of samples from multiple 
species. Processes like migration and inter-breeding can create genomic
sequences that reflect alternate species trees.
Genetic events like recombination can cause
different regions of the genome to reflect different species histories 
within the same sample. This phenomenon known as Incomplete Lineage Sorting
requires us to consider a distribution of likelihoods over all possible
species trees for every position on the genome. Computing these
distributions often require complex statistical models and are
computationally expensive to compute for large sample sizes across a large
sequence. Here, we discuss a simple approach for computing exact species
tree distributions that relies on the tree sequence data model. Using tree
sequences, we can compute these results in record time and scale linearly
in the number of samples.

Tree sequences are a lossless, efficient method of storing and processing
variant data that utilizes the shared genetic material between samples.
Samples are represented as leaves in a genetic ancestral tree that spans
a particular interval of the genome. The data structure
leverages the high correlation between adjacent trees in the sequence and
stores the minimal information to transform one tree into the next. This
greatly decreases storage space and yields an efficient way to iterate through
the data.

Using this form iteration, we can design tree sequence algorithms to
recompute only the necessary information required to calculate the result
for the following tree. This approach is called an incremental algorithm
and is the reason this approach can scale to thousands (millions?) of trees
along the genome.

\section{Method}
\subsection{Ranking tree topologies}

Before we can discuss the algorithm for calculating a species trees, we
need some way to refer to and identify them uniquely, and for that we must
define species trees and uniqueness on them. In the context of this method,
we require that species trees be rooted, leaf-labelled trees with no
unary nodes.
Since there exists a finite number of topologies under this definition
of equality, we can use a combinatorial approach to index, or rank,
tree topologies in an enumeration of all possible topologies.
This rank serves as a reversible hash on species trees, meaning we can
easily convert back and forth between a tree representation and its
index among all possible species trees. The rank is used in the following
algorithms to count occurences of unique species tree topologies.

\subsection{Species tree distributions on a single tree}

The method for computing species trees distributions is inspired by the method
\twisst, which works
by repetitively selecting samples, one from each species, and tracing the
embedded tree formed by those samples in the larger gene tree. Taking each
sample to represent the species from which it was chosen, we can identify
a species tree topology. Tallying the number of sample combinations that
reflect each unique topology gives a distribution of species trees
embedded in the single gene tree. By exhausting all sample combinations,
we achieve an exact distribution.

However, this exact approach scales poorly with sample size as the number
of sample combinations for $n$ samples and $p$ populations is $O(n^p)$ for
$p \ll n$. Approximations can be obtained by running fewer iterations but
at the cost of needing to choose a fair subset of sample combinations and
account for this approximation in analyses.

Our method uses a dynamic programming approach to reduce the algorithmic
complexity to be linear in $n$, while producing an exact distribution per
combination of species in the tree.
\begin{algorithmic}
    \State state = []

    \Procedure{LeafTopology}{$u$}
        \State state[$u$] $\leftarrow$ \{(u): 0\} // The rank of a root leaf is 0
    \EndProcedure

    \Procedure{InternalTopology}{$u$}
        \State topologies = \{\}
        \State propagate child topologies  %TODO
        \State cross child topologies  %TODO
        \State state[$u$] = topologies
    \EndProcedure

    \ForAll{$u$ in leaves}
        \State \Call{LeafTopology}{$u$}
    \EndFor

    \ForAll{$u$ in postorder internal nodes}
        \State \Call{InternalTopology}{$u$}
    \EndFor
\end{algorithmic}
In the above algorithm, we compute the total topology distributions for each node
in a single pass up the tree. The savings arise when we don't need to repeat
traversals of subsets of samples 

The per-node state that we compute is bounded not by the
number of samples, but by the number of possible species trees, which is only dependent
on $p$. If we let $t(p)$ be the number of potential species trees, we see that
the algorithm complexity is
\[
    O(n \sum_{i=1}^p t(p)^2)
\]
Since $t(p)$ grows factorially, we can say that the algorithm is 
$O(n t(p)^2)$. Most importantly, this algorithm is linear in the sample size.

This algorithm also has the nice property that it works on gene trees
that have not completely coalesced. Instead of the final result being
\texttt{state[u]}, we simply take the union of the topology distributions
from each root.

\subsection{Spanning a genome}
This algorithm works well for a single tree, but becomes slow when added up
across tens or hundreds of thousands of trees as is typical in a tree sequence.
Fortunately, the substructure property allows us to reuse state between trees
where the subtree under a node is unaffected by a tree transition.
As we transition from one tree to the next, instead of constructing
the next tree from scratch we perform a Subtree-Prune-and-Regraft (SPR) operation
on the current tree to obtain the next.
When a node is removed or inserted into the tree during an SPR, we don't
need to compute the topologies within the subtree because from the perspective
of those nodes nothing has changed.
Instead we need only ``pick up'' the previous algorithm at that node and traverse
upward toward the root.
Since there is a constant number of edges removed and inserted between trees,
this process only takes $O(\log(n))$ time.

\section{Discussion}
We test this functionality by examining a \msprime{} simulation. We've simulated
a quarter million 1mb genomes distributed evenly between four species: orangutan,
gorilla, chimp and human. This produced a \tskit{} tree sequence with
INSERT TREE NUMBER trees.

To see the benefits of the incremental algorithm, we can examine the runtime for
the first tree vs the subsequent trees in the sequence.

It is worth noting that this algorithm can be used very broadly, but is optimized
for a particular use-case. The combinatorial method of ranking trees contributes
little to the overall runtime because the species trees we are ranking are very
small. More efficient indexing methods may be useful when computing on larger
numbers of species. Additionally, the higher the correlation between trees the
better the gains from using an incremental approach. Current inference methods
like \tsinfer{} can generate succinct tree sequences from variant data, but might
not currently achieve the compression extant in simulated tree sequences and thus
are slower to compute on. Nevertheless, this does mean that improvements in
inference technology have a compounding effect on the speed and accuracy
at which incremental algorithms, such as this one, operate.

\end{document}
